/**
 * http://www.w3.org/TR/2013/WD-mediacapture-streams-20130903/
 */
package org.scalajs.dom.experimental.mediastream

import scala.scalajs.js
import org.scalajs.dom.raw.{DOMError, Event, EventTarget}
import scala.scalajs.js.annotation.JSName
import scala.scalajs.js.|

/**
 * The MediaStream
 *
 * http://www.w3.org/TR/2013/WD-mediacapture-streams-20130903/#mediastream
 *
 * http://www.w3.org/TR/2013/WD-mediacapture-streams-20130903/#mediastream
 *
 * http://www.w3.org/TR/2013/WD-mediacapture-streams-20130903/#mediastream
 *
 * MDN
 *
 */
@js.native
class MediaStream() extends EventTarget {

  /**
   * READONLY Is a Boolean value set to true if the ended event has been
   * fired on the object, meaning that the stream has been completely read,
   * or false if the end of the stream has not been reached.
   *
   * MDN
   */
  val ended: Boolean = js.native

  /**
   * READONLY Is a DOMString containing 36 characters denoting a universally
   * unique identifier (UUID) for the object.
   *
   * MDN
   */
  val id: String = js.native

  /**
   * Is an EventHandler containing the action to perform when an addtrack event
   * is fired when a new MediaStreamTrack object is added.
   *
   * MDN
   */
  var onaddtrack: js.Function1[Event, Any] = js.native

  /**
   * Is an EventHandler containing the action to perform when an removetrack
   * event is fired when a  MediaStreamTrack object is removed from it.
   *
   * MDN
   */
  var onremovetrack: js.Function1[Event, Any] = js.native

  /**
   * Stores a copy of the MediaStreamTrack given as argument. If the track has
   * already been added to the MediaStream object, nothing happens; if the
   * track is in the finished state - that is, has already reached its end -
   * the exception INVALID_STATE_RAISE is raised.
   *
   * MDN
   */
  def addTrack(track: MediaStreamTrack): Unit = js.native

  /**
   * Returns a list of the MediaStreamTrack objects stored in the MediaStream
   * object that have their kind attribute set to "audio". The order is not
   * defined, and may not only vary from one browser to another, but also from
   * one call to another..
   *
   * MDN
   */
  def getAudioTracks(): js.Array[MediaStreamTrack] = js.native

  /**
   * Returns the track whose ID corresponds to the one given in parameters,
   * trackid. If no parameter is given, or if no track with that ID does exist,
   * it returns null. If several tracks have the same ID, it returns the first
   * one.
   *
   * MDN
   */
  def getTrackById(id :String): MediaStreamTrack = js.native

  /**
   * Returns a list of the MediaStreamTrack objects stored in the MediaStream
   * object that have their kind attribute set to "video". The order is not
   * defined, and may not only vary from one browser to another, but also from
   * one call to another.
   *
   * MDN
   */
  def getVideoTracks(): js.Array[MediaStreamTrack] = js.native

  /**
   * Removes the MediaStreamTrack given as argument. If the track is not part
   * of the MediaStream object, nothing happens; if the track is in the
   * finished state - that is, it has already reached its end - the exception
   * INVALID_STATE_RAISE is raised.
   *
   * MDN
   */
  def removeTrack(track: MediaStreamTrack): Unit = js.native
}

@js.native
class MediaStreamEvent(`type`: String, ms: js.Dictionary[js.Any] ) extends Event {
  val stream: MediaStream = js.native
}

@js.native
trait MediaStreamTrack extends EventTarget {

  /**
   * Is a Boolean value with a value of true if the track is enabled, that is
   * allowed to render the media source stream; or false if it is disabled,
   * that is not rendering the media source stream but silence and blackness.
   * If the track has been disconnected, this value can be changed but has no
   * more effect.
   *
   * MDN
   */
  var enabled: Boolean = js.native

  /**
   * READONLY Returns a DOMString containing a unique identifier (GUID) for the
   * track; it is generated by the browser.
   *
   * MDN
   */
  val id: String = js.native

  /**
   * READONLY Returns a DOMString set to "audio" if the track is an audio track
   * and to "video", if it is a video track. It doesn't change if the track is
   * deassociated from its source.
   *
   * MDN
   */
  val kind: String = js.native

  /**
   * READONLY Returns a DOMString containing a user agent-assigned label that
   * identifies the track source, as in "internal microphone". The string may
   * be left empty and is empty as long as no source has been connected. When
   * the track is deassociated from its source, the label is not changed.
   *
   * MDN
   */
  val label: String = js.native

  /**
   * READONLY Returns a Boolean value with a value of true if the track is
   * muted, false otherwise.
   *
   * MDN
   */
  val muted: Boolean = js.native

  /**
   * READONLY Returns a Boolean value with a value of true if the track is
   * readonly (such a video file source or a camera that settings can't be
   * modified),false otherwise.
   *
   * MDN
   */
  val readonly: Boolean = js.native

  /**
   * READONLY Returns an enumerated value giving the status of the track.It
   * takes one of the following values:
   *
   *    "live" which indicates that an input is connected and does its
   *    best-effort in providing real-time data. In that case, the output of
   *    data can be switched on or off using the MediaStreamTrack.enabled
   *    attribute.
   *
   *    "ended" which indicates that the input is not giving any more data
   *    and will never provide new data.
   *
   * MDN
   */
  val readyState: String = js.native

  /**
   * READONLY Returns a boolean value with a value of true if the track is
   * sourced by a RTCPeerConnection, false otherwise.
   *
   * MDN
   */
  val remote: Boolean = js.native

  /**
   * Is a EventHandler containing the action to perform when an started event
   * is fired on the object, that is when a new MediaStreamTrack object is
   * added.
   *
   * MDN
   */
  var onstarted: js.Function1[Event, Any] = js.native

  /**
   * Is a EventHandler containing the action to perform when an mute event is
   * fired on the object, that is when the streaming is terminating.
   *
   * MDN
   */
  var onmute: js.Function1[Event, Any] = js.native

  /**
   * Is a EventHandler containing the action to perform when an unmute event
   * is fired on the object, that is when a  MediaStreamTrack object is removed
   * from it.
   *
   * MDN
   */
  var onunmute: js.Function1[Event, Any] = js.native

  /**
   * Is a EventHandler containing the action to perform when an overconstrained
   * event is fired on the object, that is when a  MediaStreamTrack object is
   * removed from it.
   *
   * MDN
   */
  var onoverconstrained: js.Function1[Event, Any] = js.native

  /**
   * Is a EventHandler containing the action to perform when an ended event is
   * fired on the object, that is when a  MediaStreamTrack object is removed
   * from it.
   *
   * MDN
   */
  var oneended: js.Function1[Event, Any] = js.native

  /**
   * getSourceInfos, static
   * Returns authorized information for all available sources.
   * No parameters.
   */
  def getSourceInfos(): js.Array[SourceInfo] = js.native

  def constraints(): MediaTrackConstraints = js.native

  def states(): AllVideoCapabilities | AllAudioCapabilities = js.native

  def capabilities(): js.Any = js.native

  def applyConstraints(constraints: MediaTrackConstraints): Unit = js.native

  /**
   * Stops playing the source associated to the track, both the source and the
   * track are deassociated. The track state is set to ended.
   *
   * MDN
   */
  def stop(): Unit = js.native
}

@js.native
trait AllVideoCapabilities extends js.Object {
  // TODO:...
}

@js.native
trait AllAudioCapabilities extends js.Object {
  // TODO:...
}

@js.native
trait MediaSourceStates extends js.Object {
  var sourceType: String = js.native
  var sourceId: String = js.native
  var width: Long = js.native
  var height: Long = js.native
  var frameRate: Double = js.native
  var aspectRatio: Double = js.native
  var facingMode: String = js.native
  var volume: Long = js.native
}

object MediaSourceStates{
  object SourceType{
    val none = "none"
    val camera = "camera"
    val microphone = "microphone"
  }

  object VideoFacingMode{
    val user = "user"
    val environment = "environment"
    val left = "left"
    val right = "right"
  }

  def apply(
      sourceType: js.UndefOr[String] = js.undefined,
      sourceId: js.UndefOr[String] = js.undefined,
      width: js.UndefOr[Long] = js.undefined,
      height: js.UndefOr[Long] = js.undefined,
      frameRate: js.UndefOr[Double] = js.undefined,
      aspectRatio: js.UndefOr[Double] = js.undefined,
      facingMode: js.UndefOr[String] = js.undefined,
      volume: js.UndefOr[Long] = js.undefined): MediaSourceStates = {
    val result = js.Dynamic.literal()
    sourceType.foreach(result.sourceType = _)
    sourceId.foreach(result.sourceId = _)
    width.foreach(result.width = _)
    height.foreach(result.height = _)
    frameRate.foreach(result.frameRate = _)
    aspectRatio.foreach(result.aspectRatio = _)
    facingMode.foreach(result.facingMode = _)
    volume.foreach(result.volume = _)
    result.asInstanceOf[MediaSourceStates]
  }
}

@js.native
trait MediaTrackConstraints extends js.Object {
  var mandatory: js.Dictionary[js.Any] = js.native
  var optional: js.Array[js.Dictionary[js.Any]] = js.native
}

object MediaTrackConstraints{
  def apply(
      mandatory: js.UndefOr[js.Dictionary[js.Any]] = js.undefined,
      optional: js.UndefOr[js.Array[js.Dictionary[js.Any]]] = js.undefined): MediaTrackConstraints = {
    val result = js.Dynamic.literal()
    mandatory.foreach(result.mandatory = _)
    optional.foreach(result.optional = _)
    result.asInstanceOf[MediaTrackConstraints]
  }
}

@js.native
trait SourceInfo extends js.Object {
  var sourceId: String = js.native
  var kind: String = js.native
  var label: String = js.native
}

object SourceInfo{
  def apply(
      sourceId: js.UndefOr[Boolean] = js.undefined,
      kind: js.UndefOr[String] = js.undefined,
      label: js.UndefOr[String] = js.undefined): SourceInfo = {
    val result = js.Dynamic.literal()
    sourceId.foreach(result.sourceId = _)
    kind.foreach(result.kind = _)
    label.foreach(result.label = _)
    result.asInstanceOf[SourceInfo]
  }
}

object MediaStreamTrack {

  object kind {
    val video = "video"
    val audio = "audio"
  }

  object MediaStreamTrackState {
    val `new` = "new"
    val live = "live"
    val ended = "ended"
  }

  def apply(
      enabled: js.UndefOr[Boolean] = js.undefined,
      id: js.UndefOr[String] = js.undefined,
      kind: js.UndefOr[String] = js.undefined,
      label: js.UndefOr[String] = js.undefined,
      muted: js.UndefOr[Boolean] = js.undefined,
      readonly: js.UndefOr[Boolean] = js.undefined,
      readyState: js.UndefOr[String] = js.undefined,
      remote: js.UndefOr[Boolean] = js.undefined,
      onstarted: js.UndefOr[js.Function0[Any]] = js.undefined,
      onmute: js.UndefOr[js.Function0[Any]] = js.undefined,
      onunmute: js.UndefOr[js.Function0[Any]] = js.undefined,
      onoverconstrained: js.UndefOr[js.Function0[Any]] = js.undefined,
      oneended: js.UndefOr[js.Function0[Any]] = js.undefined): MediaStreamTrack = {
    val result = js.Dynamic.literal()
    enabled.foreach(result.enabled = _)
    id.foreach(result.id = _)
    kind.foreach(result.kind = _)
    label.foreach(result.label = _)
    muted.foreach(result.muted = _)
    readonly.foreach(result.readonly = _)
    readyState.foreach(result.readyState = _)
    remote.foreach(result.remote = _)
    onstarted.foreach(result.onstarted = _)
    onmute.foreach(result.onmute = _)
    onunmute.foreach(result.onunmute = _)
    onoverconstrained.foreach(result.onoverconstrained = _)
    oneended.foreach(result.oneended = _)
    result.asInstanceOf[MediaStreamTrack]
  }
}

@js.native
trait MediaStreamConstraints extends js.Object {
  var video: Boolean | MediaTrackConstraints = js.native
  var audio: Boolean | MediaTrackConstraints = js.native
  var peerIdentity: String = js.native
}

object MediaStreamConstraints {
  def apply(
             video: js.UndefOr[Boolean | MediaTrackConstraints] = js.undefined,
             audio: js.UndefOr[Boolean | MediaTrackConstraints] = js.undefined,
             peerIdentity: js.UndefOr[String] = js.undefined): MediaStreamConstraints = {
    val result = js.Dynamic.literal()
    video.foreach(v => result.video = v.asInstanceOf[js.Any])
    audio.foreach(a => result.audio = a.asInstanceOf[js.Any])
    peerIdentity.foreach(result.peerIdentity = _)
    result.asInstanceOf[MediaStreamConstraints]
  }
}

@JSName("window.navigator")
@js.native
trait NavigatorMediaStream extends js.Object {

  def getUserMedia(constraints: MediaStreamConstraints, success: js.Function1[MediaStream, Any], error: js.Function1[DOMError, Any] ): Unit = js.native
}
